#version 460
#extension GL_GOOGLE_include_directive : enable
#extension GL_KHR_vulkan_glsl : enable

#include "svgf_edge_functions.glsl"
#include "common.glsl"
#include "brdf.glsl"

layout (local_size_x = 8, local_size_y = 8) in;

layout(set = 0, binding = 0) uniform _CameraBuffer { GPUCameraData cameraData; };

// Current Reprojection Write DS

layout(set = 1, binding = 0) uniform sampler2D gbufferAlbedoMetallic;
layout(set = 1, binding = 1) uniform sampler2D gbufferNormalMotion;
layout(set = 1, binding = 2) uniform sampler2D gbufferRoughnessDepthCurvatureMaterial;
layout(set = 1, binding = 3) uniform sampler2D gbufferUV;
layout(set = 1, binding = 4) uniform sampler2D gbufferDepth;

layout(set = 2, binding = 0) uniform sampler2D prev_gbufferAlbedoMetallic;
layout(set = 2, binding = 1) uniform sampler2D prev_gbufferNormalMotion;
layout(set = 2, binding = 2) uniform sampler2D prev_gbufferRoughnessDepthCurvatureMaterial;
layout(set = 2, binding = 3) uniform sampler2D prev_gbufferUV;
layout(set = 2, binding = 4) uniform sampler2D prev_gbufferDepth;

// Input DS
layout(set = 3, binding = 0) uniform sampler2D raytracingResult;

// Prev Output
layout(set = 4, binding = 0) uniform sampler2D historyOutput;
layout(set = 4, binding = 1) uniform sampler2D historyMoments;

layout(set = 5, binding = 0, rgba16f) uniform writeonly image2D currOutput;
layout(set = 5, binding = 1, rgba16f) uniform writeonly image2D currMoments;

#define NORMAL_DISTANCE 0.1f
#define PLANE_DISTANCE 5.0f

#define ALPHA 0.01f
#define MOMENTS_ALPHA 0.2f

#define VALID_WEIGHT 0.00001F

bool plane_distance_disocclusion_check(vec3 current_pos, vec3 history_pos, vec3 current_normal)
{
    vec3  to_current    = current_pos - history_pos;
    float dist_to_plane = abs(dot(to_current, current_normal));

    return dist_to_plane > PLANE_DISTANCE;
}

// ------------------------------------------------------------------------

bool out_of_frame_disocclusion_check(ivec2 coord, ivec2 image_dim)
{
    // check whether reprojected pixel is inside of the screen
    if (any(lessThan(coord, ivec2(0, 0))) || any(greaterThan(coord, image_dim - ivec2(1, 1))))
        return true;
    else
        return false;
}

// ------------------------------------------------------------------------

bool mesh_id_disocclusion_check(float mesh_id, float mesh_id_prev)
{
    if (mesh_id == mesh_id_prev)
        return false;
    else
        return true;
}

// ------------------------------------------------------------------------

bool normals_disocclusion_check(vec3 current_normal, vec3 history_normal)
{
    if (pow(abs(dot(current_normal, history_normal)), 2) > NORMAL_DISTANCE)
        return false;
    else
        return true;
}

// ------------------------------------------------------------------------

bool is_reprojection_valid(ivec2 coord, vec3 current_pos, vec3 history_pos, vec3 current_normal, vec3 history_normal, float current_mesh_id, float history_mesh_id, ivec2 image_dim)
{
    // check if the history sample is within the frame
    if (out_of_frame_disocclusion_check(coord, image_dim)) return false;

    // check if the history belongs to the same surface
    if (mesh_id_disocclusion_check(current_mesh_id, history_mesh_id)) return false;

    // check if history sample is on the same plane
    if (plane_distance_disocclusion_check(current_pos, history_pos, current_normal)) return false;

    // check normals for compatibility
    if (normals_disocclusion_check(current_normal, history_normal)) return false;

    return true;
}

// ------------------------------------------------------------------

vec2 virtual_point_reprojection(ivec2 current_coord, ivec2 size, float depth, float ray_length, vec3 cam_pos, mat4 view_proj_inverse, mat4 prev_view_proj)
{
    const vec2 tex_coord  = current_coord / vec2(size);
    vec3       ray_origin = world_position_from_depth(tex_coord, depth, view_proj_inverse);

    vec3 camera_ray = ray_origin - cam_pos.xyz;

    float camera_ray_length     = length(camera_ray);
    float reflection_ray_length =  ray_length;

    camera_ray = normalize(camera_ray);

    vec3 parallax_hit_point = cam_pos.xyz + camera_ray * (camera_ray_length + reflection_ray_length);

    vec4 reprojected_parallax_hit_point = prev_view_proj * vec4(parallax_hit_point, 1.0f);

    reprojected_parallax_hit_point.xy /= reprojected_parallax_hit_point.w;

    return (reprojected_parallax_hit_point.xy * 0.5f + 0.5f) * vec2(size);
}

// ------------------------------------------------------------------------

vec2 compute_history_coord(ivec2 current_coord, ivec2 size, float depth, vec2 motion, float curvature, float ray_length, vec3 cam_pos, mat4 view_proj_inverse, mat4 prev_view_proj, bool useVirtual)
{
    if(useVirtual) {
        return virtual_point_reprojection(current_coord, size, depth, ray_length, cam_pos, view_proj_inverse, prev_view_proj);
    }
    return vec2(current_coord) + motion.xy * vec2(size);
}

bool loadPrevData(out vec4 prevIndirect, out vec2 prevMoments, out float historyLength, float rayLength, bool useVirtual, vec3 mean, vec3 stddev, out float weight)
{
    const ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
    const vec2 imageDim = textureSize(raytracingResult, 0);

    const vec2 pixelCenter = ipos + vec2(0.5f);
    const vec2 texCoord = pixelCenter / vec2(imageDim);

    vec4 gb1 = texelFetch(gbufferAlbedoMetallic, ipos, 0);
    vec4 gb2 = texelFetch(gbufferNormalMotion, ipos, 0);
    vec4 gb3 = texelFetch(gbufferRoughnessDepthCurvatureMaterial, ipos, 0);

    float depth = texelFetch(gbufferDepth, ipos, 0).r;
    const vec2 motion = gb2.zw;

    const vec3 current_normal = octohedral_to_direction(gb2.xy);
    const float current_mesh_id = gb3.w;
    const vec3 current_pos = world_position_from_depth(texCoord, depth, cameraData.viewprojInverse);

    const float curvature = gb3.b;
    const vec2 texPrevCoord = texCoord + motion.xy;
    const vec2 reprojected_coord = compute_history_coord(ipos, 
                                                            ivec2(imageDim), 
                                                            depth, 
                                                            motion, 
                                                            curvature, 
                                                            rayLength, 
                                                            cameraData.cameraPos.xyz, 
                                                            cameraData.viewprojInverse, 
                                                            cameraData.prevViewproj,
                                                            useVirtual);   
    const ivec2 iposPrev = ivec2(reprojected_coord);                                                      
    const vec2  posPrev = reprojected_coord;                                                                                                         


    prevIndirect = vec4(0,0,0,0);
    prevMoments  = vec2(0,0);

    bool v[4];
    ivec2 offset[4] = { ivec2(0, 0), ivec2(1, 0), ivec2(0, 1), ivec2(1, 1) };
    

    // check for all 4 taps of the bilinear filter for validity
	bool valid = false;
    for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
    { 
        ivec2 loc = ivec2(posPrev) + offset[sampleIdx];
        vec4 prev_gb1 = texelFetch(prev_gbufferAlbedoMetallic, loc, 0);
        vec4 prev_gb2 = texelFetch(prev_gbufferNormalMotion, loc, 0);
        vec4 prev_gb3 = texelFetch(prev_gbufferRoughnessDepthCurvatureMaterial, loc, 0);

        float history_depth = texelFetch(prev_gbufferDepth, loc, 0).r;
        const vec2 motion = prev_gb2.zw;

        const vec3 history_normal = octohedral_to_direction(prev_gb2.xy);
        const float history_mesh_id = prev_gb3.w;
        const vec3 history_pos = world_position_from_depth(texPrevCoord, history_depth, cameraData.viewprojInverse);

        v[sampleIdx] = is_reprojection_valid(iposPrev, current_pos, history_pos, current_normal, history_normal, current_mesh_id, history_mesh_id, ivec2(imageDim));

        valid = valid || v[sampleIdx];
    }    

    if (valid) 
    {
        float sumw = 0;
        float x = fract(posPrev.x);
        float y = fract(posPrev.y);

        // bilinear weights
        float w[4] = { (1 - x) * (1 - y), 
                            x  * (1 - y), 
                       (1 - x) *      y,
                            x  *      y };

        prevIndirect = vec4(0,0,0,0);
        prevMoments  = vec2(0,0);

        // perform the actual bilinear interpolation
        for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
        {
            ivec2 loc = ivec2(posPrev) + offset[sampleIdx];            
            if (v[sampleIdx])
            {
                vec4 color = texelFetch(historyOutput, loc, 0);
                vec3 rgb_dist = abs(color.rgb - mean) / stddev;
                float lumWeight = exp2(-10 * luminance(rgb_dist));

                float sampleWeight = w[sampleIdx] * lumWeight;
                prevIndirect += sampleWeight * color;
                prevMoments  += sampleWeight * texelFetch(historyMoments, loc, 0).xy;
                sumw         += sampleWeight;
            }
        }

		// redistribute weights in case not all taps were used
		valid = (sumw >= VALID_WEIGHT);
		prevIndirect = valid ? prevIndirect / sumw : vec4(0, 0, 0, 0);
		prevMoments  = valid ? prevMoments / sumw  : vec2(0, 0);
        weight = valid ? sumw : 0;
    }
    
    if(!valid) // perform cross-bilateral filter in the hope to find some suitable samples somewhere
    {
        float cnt = 0.0;

        // this code performs a binary descision for each tap of the cross-bilateral filter
        const int radius = 1;
        for (int yy = -radius; yy <= radius; yy++)
        {
            for (int xx = -radius; xx <= radius; xx++)
            {
                ivec2 p = iposPrev + ivec2(xx, yy);
                vec4 prev_gb1 = texelFetch(prev_gbufferAlbedoMetallic, p, 0);
                vec4 prev_gb2 = texelFetch(prev_gbufferNormalMotion, p, 0);
                vec4 prev_gb3 = texelFetch(prev_gbufferRoughnessDepthCurvatureMaterial, p, 0);

                float history_depth = texelFetch(prev_gbufferDepth, p, 0).r;
                const vec2 motion = prev_gb2.zw;

                const vec3 history_normal = octohedral_to_direction(prev_gb2.xy);
                const float history_mesh_id = prev_gb3.z;
                const vec3 history_pos = world_position_from_depth(texPrevCoord, history_depth, cameraData.viewprojInverse);

                if ( is_reprojection_valid(iposPrev, current_pos, history_pos, current_normal, history_normal, current_mesh_id, history_mesh_id, ivec2(imageDim)))
                {
                    vec4 color = texelFetch(historyOutput, p, 0);
                    vec3 rgb_dist = abs(color.rgb - mean) / stddev;
                    float lumWeight = exp2(-10 * luminance(rgb_dist));

                    prevIndirect += lumWeight * texelFetch(historyOutput, p, 0);
					prevMoments += lumWeight * texelFetch(historyMoments, p, 0).xy;
                    cnt += 1.0 * lumWeight;
                }
            }
        }
        if (cnt > 0)
        {
            valid = true;
            prevIndirect /= cnt;
            prevMoments  /= cnt;
        }

    }
    
    //if(gb3.r < 0.05) {
    //    valid = false;
    //}

    if (valid)
    {
        historyLength = texelFetch(historyMoments, iposPrev, 0).b;
    }
    else
    {
        prevIndirect = vec4(0,0,0,0);
        prevMoments = vec2(0,0);
        historyLength = 0;
    }

    return valid;
}

float luminance_weight(vec3 val) {
    float luma = luminance(val.xyz);
    float weight = max(exp(-luma * 0.3), 1.0e-2);
    return weight;
}

vec3 fireflyRejectionVariance(vec3 radiance, vec3 variance, vec3 shortMean, vec3 stddev)
{
    vec3 dev = sqrt(max(vec3(1.0e-5), variance));
    vec3 highThreshold = vec3(0.1) + shortMean + stddev * 8.0;
    vec3 overflow = max(vec3(0.0), radiance - highThreshold);
    return radiance - overflow;
}

vec3 clip_aabb(vec3 aabb_min, vec3 aabb_max, vec3 history_sample)
{
    // Note: only clips towards aabb center
    vec3 aabb_center = 0.5f * (aabb_max + aabb_min);
    vec3 extent_clip = 0.5f * (aabb_max - aabb_min) + 0.001f;

    // Find color vector
    vec3 color_vector = history_sample - aabb_center;
    // Transform into clip space
    vec3 color_vector_clip = color_vector / extent_clip;
    // Find max absolute component
    color_vector_clip  = abs(color_vector_clip);
    float max_abs_unit = max(max(color_vector_clip.x, color_vector_clip.y), color_vector_clip.z);

    if (max_abs_unit > 1.0)
        return aabb_center + color_vector / max_abs_unit; // clip towards color vector
    else
        return history_sample; // point is inside aabb
}

void main()
{
    const ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
    vec4 indirect_raylength = texelFetch(raytracingResult, ipos, 0).rgba;
    vec3 indirect = indirect_raylength.rgb;
    float rayLength = indirect_raylength.a;

    // Mean, variance, stddev
    vec4 m1 = vec4(0.0);
	vec4 m2 = vec4(0.0);
    int sampleCount = 8;
	for (int x = -sampleCount; x <= sampleCount; x++)
	{
		for (int y = -sampleCount; y <= sampleCount; y++)
		{
			ivec2 offset = ivec2(x, y);
			ivec2 coord = ipos + offset;

			vec4 sampleColor = texelFetch(raytracingResult, coord, 0).rgba;

			m1 += sampleColor;
			m2 += sampleColor * sampleColor;
		}
	}

	vec4 mean = m1 / pow(sampleCount * 2 + 1, 2);
	vec4 var = (m2 / pow(sampleCount * 2 + 1, 2)) - (mean * mean);
	vec4 stddev = sqrt(max(var, 0.0f));

    float historyLength = 0;
    vec4 prevIndirect = vec4(0);
    vec2 prevMoments = vec2(0);
    bool success = false;

    {
        float weight1 = 0;
        float historyLength1 = 0;
        vec4 prevIndirect1 = vec4(0);
        vec2 prevMoments1 = vec2(0);
	    bool success1 = loadPrevData(prevIndirect1, prevMoments1, historyLength1, rayLength, false, mean.rgb, stddev.rgb, weight1);

        float weight2 = 0;
        float historyLength2 = 0;
        vec4 prevIndirect2 = vec4(0);
        vec2 prevMoments2 = vec2(0);
	    bool success2 = loadPrevData(prevIndirect2, prevMoments2, historyLength2, rayLength, true, mean.rgb, stddev.rgb, weight2);

        if(texelFetch(gbufferRoughnessDepthCurvatureMaterial, ipos, 0).b > 0.001) {
            weight2 = 0;
        }

        success = success1 || success2;

        if(weight1 + weight2 > VALID_WEIGHT) {
            prevIndirect = (prevIndirect1 * weight1 + prevIndirect2 * weight2) / (weight1 + weight2);
            prevMoments = (prevMoments1 * weight1 + prevMoments2 * weight2) / (weight1 + weight2);
            historyLength = max(historyLength1, historyLength2);
        }
    }


    float roughness = texelFetch(gbufferRoughnessDepthCurvatureMaterial, ipos, 0).r;
    float s_max_samples = max(8.0, 32 * ((1.0 - exp(-roughness * 100.0))));
	historyLength = min(s_max_samples, historyLength + 1.0f);

    indirect = fireflyRejectionVariance(indirect, var.rgb, mean.rgb, stddev.rgb);

    //weight two approaches?
    //vec3 dist = (indirect.rgb - mean.rgb) / stddev.rgb;
    //float reprojectionApproachWeight = exp2(-10 * luminance(dist));

    // this adjusts the alpha for the case where insufficient history is available.
    // It boosts the temporal accumulation to give the samples equal weights in
    // the beginning.
    float alpha        = 1.0 / historyLength;
    float alphaMoments = 1.0 / historyLength;

    //float luminanceWeight = luminance_weight(indirect);
    //alpha *= luminanceWeight;
    //alphaMoments *= luminanceWeight;

    // compute first two moments of luminance
    vec2 moments;
    moments.r = luminance(indirect);
    moments.g = moments.r * moments.r;

    // temporal integration of the moments
    moments = mix(prevMoments, moments, alphaMoments);

    float variance = max(0.0f, moments.g - moments.r * moments.r);

    // temporal integration of radiance
    //color box clamping
    if(success) {
        vec4 colorMin = mean - stddev * 1;
	    vec4 colorMax = mean + stddev * 1;
	    prevIndirect.rgb = clip_aabb(colorMin.rgb, colorMax.rgb, prevIndirect.rgb);
    }
    vec4 accumulated_color = mix(prevIndirect, vec4(indirect, 0), alpha);
    
    imageStore(currMoments, ivec2(gl_GlobalInvocationID.xy), vec4(moments, historyLength, 0.0f));
    imageStore(currOutput, ivec2(gl_GlobalInvocationID.xy), vec4(accumulated_color.xyz, variance));
}
